diff --git a/src/latch.rs b/src/latch.rs
index cf5665a..69e8b27 100644
--- a/src/latch.rs
+++ b/src/latch.rs
@@ -16,6 +16,17 @@ use std::sync::{Mutex, Condvar};
 ///
 /// It'd probably be better to refactor the API into two paired types,
 /// but that's a bit of work, and this is not a public API.
+///
+/// ## Memory ordering
+///
+/// Latches need to guarantee two things:
+///
+/// - Once `probe()` returns true, all memory effects from the `set()`
+///   are visible (in other words, the set should synchronize-with
+///   the probe).
+/// - Once `set()` occurs, the next `probe()` *will* observe it.  This
+///   typically requires a seq-cst ordering. See [the "tickle-then-get-sleepy" scenario in the sleep
+///   README](/src/sleep/README.md#tickle-then-get-sleepy) for details.
 pub trait Latch {
     /// Test if the latch is set.
     fn probe(&self) -> bool;
@@ -41,12 +52,12 @@ impl SpinLatch {
 impl Latch for SpinLatch {
     #[inline]
     fn probe(&self) -> bool {
-        self.b.load(Ordering::Acquire)
+        self.b.load(Ordering::SeqCst)
     }
 
     #[inline]
     fn set(&self) {
-        self.b.store(true, Ordering::Release);
+        self.b.store(true, Ordering::SeqCst);
     }
 }
 
@@ -117,12 +128,12 @@ impl Latch for CountLatch {
     #[inline]
     fn probe(&self) -> bool {
         // Need to acquire any memory reads before latch was set:
-        self.counter.load(Ordering::Acquire) == 0
+        self.counter.load(Ordering::SeqCst) == 0
     }
 
     /// Set the latch to true, releasing all threads who are waiting.
     #[inline]
     fn set(&self) {
-        self.counter.fetch_sub(1, Ordering::Release);
+        self.counter.fetch_sub(1, Ordering::SeqCst);
     }
 }
diff --git a/src/sleep/README.md b/src/sleep/README.md
index 7d47c4d..4e8a429 100644
--- a/src/sleep/README.md
+++ b/src/sleep/README.md
@@ -41,7 +41,7 @@ Workers interact with the sleep module by invoking three methods:
   been pushed to the local deque) or that some other blocking
   condition has been resolved (e.g., a latch has been set). Wakes up any
   sleeping workers.
-  
+
 When in a loop searching for work, Workers also have to maintain an
 integer `yields` that they provide to the `sleep` module (which will
 return a new value for the next time). Thus the basic worker "find
@@ -117,7 +117,7 @@ events that can allow a blocked worker to make progress:
    task could be uninjected and executed.
 3. A latch is set. One of the sleeping workers might have been waiting for
    that before it could go on.
-   
+
 Whenever one of these things happens, the worker (or thread, more generally)
 responsible must invoke `tickle()`. Tickle will basically wake up **all**
 the workers:
@@ -130,14 +130,14 @@ the workers:
   `notify_all()` on the condition variable, which will cause them to
   awaken and start over from the awake state (with a yield counter of
   zero).
-  
+
 Because `tickle()` is invoked very frequently -- and hopefully most of
 the time it is not needed, because the workers are already actively
 stealing -- it is important that it be very cheap. The current design
 requires, in the case where nobody is even sleepy, just a load and a
-compare. If there are sleepy workers, a `Release` store is needed.  If
-there workers *asleep*, we must naturally acquire the lock and signal
-the condition variable.
+compare. If there are sleepy workers, a swap is needed.  If there
+workers *asleep*, we must naturally acquire the lock and signal the
+condition variable.
 
 # The global state
 
@@ -168,12 +168,221 @@ Some examples:
 - `2`: no workers are asleep, but worker 0 is sleepy (`(0 + 1) << 1 == 2`).
 - `3`: some workers are asleep, and worker 0 is sleepy.
 
+# Correctness level 1: avoiding deadlocks etc
+
+In general, we do not want to miss wakeups. Two bad things could happen:
+
+- **Suboptimal performance**: If this is a wakeup about a new job being
+  pushed into a local deque, it won't deadlock, but it will cause
+  things to run slowly. The reason that it won't deadlock is that we
+  know at least one thread is active (the one doing the pushing), and
+  it will (sooner or later) try to pop this item from its own local
+  deque.
+- **Deadlocks:** If this is a wakeup about an injected job or a latch that got set, however,
+  this can cause deadlocks. In the former case, if a job is injected but no thread ever
+  wakes to process it, the injector will likely block forever. In the latter case,
+  imagine this scenario:
+  - thread A calls join, forking a task T1, then executing task T2
+  - thread B steals T1, forks a task T3, and executes T4.
+  - thread A completes task T2 and blocks on T1
+  - thread A steals task T3 from thread B
+  - thread B finishes T4 and goes to sleep, blocking on T3
+  - thread A completes task T3 and makes a wakeup, but it gets lost
+  At this point, thread B is still asleep and will never signal T2, so thread A will itself
+  go to sleep. Bad.
+
+It turns out that guaranteeing we don't miss a wakeup while retaining
+good performance is fairly tricky. This is because of some details of
+the C++11 memory model. But let's ignore those for now and generally
+assume sequential consistency. In that case, our scheme should work
+perfectly.
+
+Even if you assume seqcst, though, ensuring that you don't miss
+wakeups can be fairly tricky in the absence of a central queue. For
+example, consider the simplest scheme: imagine we just had a boolean
+flag indicating whether anyone was asleep. Then you could imagine that
+when workers find no work, they flip this flag to true. When work is
+published, if the flag is true, we issue a wakeup.
+
+The problem here is that checking for new work is not an atomic
+action. So it's possible that worker 1 could start looking for work
+and (say) see that worker 0's queue is empty and then search workers
+2..N.  While that searching is taking place, worker 0 publishes some
+new work.  At the time when the new work is published, the "anyone
+sleeping?" flag is still false, so nothing happens. Then worker 1, who
+failed to find any work, goes to sleep --- completely missing the wakeup!
+
+We use the "sleepy worker" idea to sidestep this problem. Under our
+scheme, instead of going right to sleep at the end, worker 1 would
+become sleepy.  Worker 1 would then do **at least** one additional
+scan. During this scan, they should find the work published by worker
+0, so they will stop being sleepy and go back to work (here of course
+we are assuming that no one else has stolen the worker 0 work yet; if
+someone else stole it, worker 1 may still go to sleep, but that's ok,
+since there is no more work to be had).
+
+Now you may be wondering -- how does being sleepy help? What if,
+instead of publishing its job right before worker 1 became sleepy,
+worker 0 wait until right before worker 1 was going to go to sleep? In
+other words, the sequence was like this:
+
+- worker 1 gets sleepy
+- worker 1 starts its scan, scanning worker 0's deque
+- worker 0 publishes its job, but nobody is sleeping yet, so no wakeups occur
+- worker 1 finshes its scan, goes to sleep, missing the wakeup
+
+The reason that this doesn't occur is because, when worker 0 publishes
+its job, it will see that there is a sleepy worker. It will clear the
+global state to 0.  Then, when worker 1 its scan, it will notice that
+it is no longer sleepy, and hence it will not go to sleep. Instead it
+will awaken and keep searching for work.
+
+The sleepy worker phase thus also serves as a cheap way to signal that
+work is around: instead of doing the whole dance of acquiring a lock
+and issuing notifications, when we publish work we can just swap a
+single atomic counter and let the sleepy worker notice that on their
+own.
+
+## Beyond seq-cst
+
+Unfortunately, the C++11 memory model doesn't generally guarantee
+seq-cst. And, somewhat annoyingly, it's not easy for the sleep module
+**in isolation** to guarantee the properties the need. The key
+challenge has to do with the *synchronized-with* relation. Typically,
+we try to use acquire-release reasoning, and in that case the idea is
+that **if** a load observes a store, it will also observe those writes
+that preceded the store. But nothing says that the load **must**
+observe the store -- at least not right away.
+
+The place that this is most relevant is the load in the `tickle()`
+routine. The routine begins by reading from the global state. If it
+sees anything other than 0, it then does a swap and -- if necessary --
+acquires a lock and does a notify. This load is a seq-cst load (as are
+the other accesses in tickle). This ensures that it is sensible to
+talk about a tickle happening *before* a worker gets sleepy and so
+forth.
+
+It turns out that to get things right, if we use the current tickle
+routine, we have to use seq-cst operations **both in the sleep module
+and when publishing work**. We'll walk through two scenarios to
+show what I mean. 
+
+### Scenario 1: get-sleepy-then-get-tickled
+
+This scenario shows why the operations in sleep must be seq-cst. We
+want to ensure that once a worker gets sleepy, any other worker that
+does a tickle will observe that. In other words, we want to ensure
+that the following scenario **cannot happen**:
+
+1. worker 1 is blocked on latch L
+2. worker 1 becomes sleepy
+    - becoming sleepy involves a CAS on the global state to set it to 4 ("worker 1 is sleepy")
+3. worker 0 sets latch L
+4. worker 0 tickles **but does not see that worker 0 is sleepy**
+
+Let's diagram this. The notation `read_xxx(A) = V` means that a read
+of location `A` was executed with the result `V`. The `xxx` is the
+ordering and the location `A` is either `L` (latch) or `S` (global
+state). I will leave the ordering on the latch as `xxx` as it is not
+relevant here. The numbers correspond to the steps above.
 
+```
+    worker 0                    worker 1
+ |                           +- 2: cas_sc(S, 4)
+s|  3: write_xxx(L)          +
+b|  4: read_sc(S) = ??? <-sc-+
+ v
+```
 
+Clearly, this cannot happen with sc orderings, because read 4 will
+always return `4` here. However, if we tried to use acquire-release
+orderings on the global state, then there would be **no guarantee**
+that the tickle will observe that a sleepy worker occurred. We would
+be guaranteed only that worker 0 would **eventually** observe that
+worker 1 had become sleepy (and, at that time, that it would see other
+writes). But it could take time -- and if we indeed miss that worker 1
+is sleepy, it could lead to deadlock or loss of efficiency, as
+explained earlier.
+
+### Scenario 2: tickle-then-get-sleepy
+
+<a name="tickle-then-get-sleepy"></a>
+
+This scenario shows why latch operations must *also* be seq-cst (and,
+more generally, any operations that publish work before a tickle). We
+wish to ensure that this ordering of events **cannot occur**:
+
+1. worker 1 is blocked on latch L
+2. worker 1 reads latch L, sees false, starts searching for work
+3. worker 0 sets latch L
+4. worker 0 tickles
+    - the tickle reads from the global state, sees 0
+5. worker 1 finishes searching, becomes sleepy
+    - becoming sleepy involves a CAS on the global state to set it to 4 ("worker 1 is sleepy")
+6. worker 1 reads latch L **but does not see that worker 0 set it**
+7. worker 1 may then proceed to become sleepy
+
+In other words, we want to ensure that if worker 0 sets a latch and
+does a tickle *before worker 1 gets sleepy*, then worker 1 will
+observe that latch as set when it calls probe. We'll see that, with
+the current scheme, this implies that the latch memory orderings must
+be seq-cst as well.
+
+Here is the diagram:
 
+```
+    worker 0                    worker 1
+ |                              2: read_xxx(L) = false
+s|  3: write_xxx(L, true)
+b|  4: read_sc(S) = 0 -+
+ |                     +-sc---> 5: cas_sc(S, 4)
+ v                              6: read_xxx(L) = ???
+```
 
-
-
-
-
-
+The diagram shows that each thread's actions are related by
+*sequenced-before* (sb). Moreover the read and write of `S` are
+related by `sc` (the seq-cst ordering). However, and this is crucial,
+this **does not** imply that oper 4 *synchronizes-with* oper 5. This
+is because a read never synchronizes-with a store, only the
+reverse. Hence, if the latch were using acq-rel orderings, it would be
+legal for oper 6 to return false. But if the latch were to use an
+**sc** ordering itself, then we know that oper 6 must return true,
+since `3 -sc-> 4 -sc-> 5 -sc-> 6`.
+
+**Note** that this means that, before we tickle, we must execute some
+seq-cst stores to publish our work (and during the scan we must load
+from those same locations) **if we wish to guarantee that the work we
+published WILL be seen by the other threads** (as opposed to
+*may*). This is true for setting a latch -- if a latch is set but
+another thread misses it, then the system could deadlock. However, in
+the case of pushing new work to a deque, we choose not to use a seqcst
+ordering. This is for several reasons:
+
+- If we miss a wakeup, the consequences are less dire: we simply run
+  less efficiently (after all, the current thread will eventually
+  complete its current task and pop the new task off the deque).
+- It is inconvenient: The deque code is beyond our control (it lies in another package). However,
+  we could create a dummy `AtomicBool` for each deque and do a seqcst write to it
+  (with whatever value) after we push to the deque, and a seqcst load whenever
+  we steal from the deque.
+- The cost of using a dummary variable was found to be quite high for some benchmarks:
+  - 8-10% overhead on nbody-parreduce
+  - 15% overhead on increment-all
+  - 40% overhead on join-recursively
+
+### Alternative solutions
+
+In both cases above, our problems arose because tickle is merely
+performing a seq-cst read. If we instead had tickle perform a release
+*swap*, that would be a write action of the global state. No matter
+the ordering mode, all writes to the same memory location have a total
+ordering, and hence we would not have to worry about others storing a
+value that we fail to read (as in scenario 1). Similarly, as a release
+write, a swap during tickle would synchronize-with a later cas and so
+scenario 2 should be averted. So you might wonder why we don't do
+that. The simple reason was that it didn't perform as well! In my
+measurements, many benchmarks were unaffected by using a swap, but
+some of them were hit hard:
+  - 8-10% overhead on nbody-parreduce
+  - 35% overhead on increment-all
+  - 245% overhead on join-recursively
diff --git a/src/sleep/mod.rs b/src/sleep/mod.rs
index 8438ee1..ec68d43 100644
--- a/src/sleep/mod.rs
+++ b/src/sleep/mod.rs
@@ -2,22 +2,11 @@
 //! for an overview.
 
 use log::Event::*;
-use std::sync::atomic::AtomicUsize;
+use std::sync::atomic::{AtomicUsize, Ordering};
 use std::sync::{Condvar, Mutex};
 use std::thread;
 use std::usize;
-use std::sync::atomic::Ordering::*;
-
-// SUBTLE CORRECTNESS POINTS
-//
-// - Can't afford a "lost" tickle, because if thread X gets sleepy
-//   and then misses a tickle, that might be the tickle to indicate that
-//   its latch is set.
-// - Sleeping while a latch is held: bad
-
-/// The "epoch" is used to handle thread activity. The idea is that we
-/// want worker threads to start to spin down when there is nothing to
-/// do, but to spin up quickly.
+
 pub struct Sleep {
     state: AtomicUsize,
     data: Mutex<()>,
@@ -58,7 +47,10 @@ impl Sleep {
 
     #[inline]
     pub fn work_found(&self, worker_index: usize, yields: usize) -> usize {
-        log!(FoundWork { worker: worker_index, yields: yields });
+        log!(FoundWork {
+            worker: worker_index,
+            yields: yields,
+        });
         if yields > ROUNDS_UNTIL_SLEEPY {
             // FIXME tickling here is a bit extreme; mostly we want to "release the lock"
             // from us being sleepy, we don't necessarily need to wake others
@@ -70,7 +62,10 @@ impl Sleep {
 
     #[inline]
     pub fn no_work_found(&self, worker_index: usize, yields: usize) -> usize {
-        log!(DidNotFindWork { worker: worker_index, yields: yields });
+        log!(DidNotFindWork {
+            worker: worker_index,
+            yields: yields,
+        });
         if yields < ROUNDS_UNTIL_SLEEPY {
             thread::yield_now();
             yields + 1
@@ -96,7 +91,11 @@ impl Sleep {
     }
 
     pub fn tickle(&self, worker_index: usize) {
-        let old_state = self.state.load(Acquire);
+        // As described in README.md, this load must be SeqCst so as to ensure that:
+        // - if anyone is sleepy or asleep, we *definitely* see that now (and not eventually);
+        // - if anyone after us becomes sleepy or asleep, they see memory events that
+        //   precede the call to `tickle()`, even though we did not do a write.
+        let old_state = self.state.load(Ordering::SeqCst);
         if old_state != AWAKE {
             self.tickle_cold(worker_index);
         }
@@ -104,8 +103,21 @@ impl Sleep {
 
     #[cold]
     fn tickle_cold(&self, worker_index: usize) {
-        let old_state = self.state.swap(AWAKE, SeqCst);
-        log!(Tickle { worker: worker_index, old_state: old_state });
+        // The `Release` ordering here suffices. The reasoning is that
+        // the atomic's own natural ordering ensure that any attempt
+        // to become sleepy/asleep either will come before/after this
+        // swap. If it comes *after*, then Release is good because we
+        // want it to see the action that generated this tickle. If it
+        // comes *before*, then we will see it here (but not other
+        // memory writes from that thread).  If the other worker was
+        // becoming sleepy, the other writes don't matter. If they
+        // were were going to sleep, we will acquire lock and hence
+        // acquire their reads.
+        let old_state = self.state.swap(AWAKE, Ordering::Release);
+        log!(Tickle {
+            worker: worker_index,
+            old_state: old_state,
+        });
         if self.anyone_sleeping(old_state) {
             let _data = self.data.lock().unwrap();
             self.tickle.notify_all();
@@ -114,20 +126,50 @@ impl Sleep {
 
     fn get_sleepy(&self, worker_index: usize) -> bool {
         loop {
-            let state = self.state.load(SeqCst);
-            log!(GetSleepy { worker: worker_index, state: state });
+            // Acquire ordering suffices here. If some other worker
+            // was sleepy but no longer is, we will eventually see
+            // that, and until then it doesn't hurt to spin.
+            // Otherwise, we will do a compare-exchange which will
+            // assert a stronger order and acquire any reads etc that
+            // we must see.
+            let state = self.state.load(Ordering::Acquire);
+            log!(GetSleepy {
+                worker: worker_index,
+                state: state,
+            });
             if self.any_worker_is_sleepy(state) {
                 // somebody else is already sleepy, so we'll just wait our turn
                 debug_assert!(!self.worker_is_sleepy(state, worker_index),
                               "worker {} called `is_sleepy()`, \
                                but they are already sleepy (state={})",
-                              worker_index, state);
+                              worker_index,
+                              state);
                 return false;
             } else {
                 // make ourselves the sleepy one
                 let new_state = self.with_sleepy_worker(state, worker_index);
-                if self.state.compare_exchange(state, new_state, SeqCst, SeqCst).is_ok() {
-                    log!(GotSleepy { worker: worker_index, old_state: state, new_state: new_state });
+
+                // This must be SeqCst on success because we want to
+                // ensure:
+                //
+                // - That we observe any writes that preceded
+                //   some prior tickle, and that tickle may have only
+                //   done a SeqCst load on `self.state`.
+                // - That any subsequent tickle *definitely* sees this store.
+                //
+                // See the section on "Ensuring Sequentially
+                // Consistency" in README.md for more details.
+                //
+                // The failure ordering doesn't matter since we are
+                // about to spin around and do a fresh load.
+                if self.state
+                    .compare_exchange(state, new_state, Ordering::SeqCst, Ordering::Relaxed)
+                    .is_ok() {
+                    log!(GotSleepy {
+                        worker: worker_index,
+                        old_state: state,
+                        new_state: new_state,
+                    });
                     return true;
                 }
             }
@@ -135,13 +177,20 @@ impl Sleep {
     }
 
     fn still_sleepy(&self, worker_index: usize) -> bool {
-        let state = self.state.load(SeqCst);
+        let state = self.state.load(Ordering::SeqCst);
         self.worker_is_sleepy(state, worker_index)
     }
 
     fn sleep(&self, worker_index: usize) {
         loop {
-            let state = self.state.load(SeqCst);
+            // Acquire here suffices. If we observe that the current worker is still
+            // sleepy, then in fact we know that no writes have occurred, and anyhow
+            // we are going to do a CAS which will synchronize.
+            //
+            // If we observe that the state has changed, it must be
+            // due to a tickle, and then the Acquire means we also see
+            // any events that occured before that.
+            let state = self.state.load(Ordering::Acquire);
             if self.worker_is_sleepy(state, worker_index) {
                 // It is important that we hold the lock when we do
                 // the CAS. Otherwise, if we were to CAS first, then
@@ -180,7 +229,23 @@ impl Sleep {
                 // awaken comes, in which case the next cycle around
                 // the loop will just return.
                 let data = self.data.lock().unwrap();
-                if self.state.compare_exchange(state, SLEEPING, SeqCst, SeqCst).is_ok() {
+
+                // This must be SeqCst on success because we want to
+                // ensure:
+                //
+                // - That we observe any writes that preceded
+                //   some prior tickle, and that tickle may have only
+                //   done a SeqCst load on `self.state`.
+                // - That any subsequent tickle *definitely* sees this store.
+                //
+                // See the section on "Ensuring Sequentially
+                // Consistency" in README.md for more details.
+                //
+                // The failure ordering doesn't matter since we are
+                // about to spin around and do a fresh load.
+                if self.state
+                    .compare_exchange(state, SLEEPING, Ordering::SeqCst, Ordering::Relaxed)
+                    .is_ok() {
                     // Don't do this in a loop. If we do it in a loop, we need
                     // some way to distinguish the ABA scenario where the pool
                     // was awoken but before we could process it somebody went
diff --git a/src/thread_pool.rs b/src/thread_pool.rs
index 146bf61..ab45690 100644
--- a/src/thread_pool.rs
+++ b/src/thread_pool.rs
@@ -13,6 +13,7 @@ use std::str::FromStr;
 use std::sync::{Arc, Mutex, Once, ONCE_INIT};
 use std::thread;
 use std::mem;
+use std::u32;
 use std::usize;
 use unwind;
 use util::leak;
@@ -208,7 +209,6 @@ impl ThreadInfo {
 
 pub struct WorkerThread {
     worker: Worker<JobRef>,
-    stealers: Vec<(usize, Stealer<JobRef>)>,
     index: usize,
 
     /// A weak random number generator.
@@ -333,9 +333,12 @@ impl WorkerThread {
         debug_assert!(self.worker.pop().is_none());
 
         // otherwise, try to steal
-        if self.stealers.is_empty() {
+        let num_threads = self.registry.thread_infos.len();
+        if num_threads <= 1 {
             return None;
         }
+        assert!(num_threads < (u32::MAX as usize),
+                "we do not support more than u32::MAX worker threads");
 
         let start = {
             // OK to use this UnsafeCell because (a) this data is
@@ -343,14 +346,15 @@ impl WorkerThread {
             // nor Sync and (b) rand crate will not call back into
             // this method.
             let rng = &mut *self.rng.get();
-            rng.next_u32() % self.stealers.len() as u32
-        };
-        let (lo, hi) = self.stealers.split_at(start as usize);
-        hi.iter()
-            .chain(lo)
-            .filter_map(|&(victim_index, ref stealer)| {
+            rng.next_u32() % num_threads as u32
+        } as usize;
+        (start .. num_threads)
+            .chain(0 .. start)
+            .filter(|&i| i != self.index)
+            .filter_map(|victim_index| {
+                let victim = &self.registry.thread_infos[victim_index];
                 loop {
-                    match stealer.steal() {
+                    match victim.stealer.steal() {
                         Stolen::Empty => return None,
                         Stolen::Abort => (), // retry
                         Stolen::Data(v) => {
@@ -367,19 +371,8 @@ impl WorkerThread {
 /// ////////////////////////////////////////////////////////////////////////
 
 unsafe fn main_loop(worker: Worker<JobRef>, registry: Arc<Registry>, index: usize) {
-    let stealers = registry.thread_infos
-        .iter()
-        .enumerate()
-        .filter(|&(i, _)| i != index)
-        .map(|(i, ti)| (i, ti.stealer.clone()))
-        .collect::<Vec<_>>();
-
-    assert!(stealers.len() < ::std::u32::MAX as usize,
-            "We assume this is not going to happen!");
-
     let worker_thread = WorkerThread {
         worker: worker,
-        stealers: stealers,
         index: index,
         rng: UnsafeCell::new(rand::weak_rng()),
         registry: registry.clone(),
